{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/cfang/.conda/envs/sae/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#### Dependencies ####\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # Only necessary for feature extraction.\n",
    "\n",
    "# Repository imports\n",
    "from ridge_utils.ridge import bootstrap_ridge\n",
    "import ridge_utils.npp\n",
    "from ridge_utils.util import make_delayed\n",
    "from ridge_utils.dsutils import make_word_ds\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "from ridge_utils.tokenization_helpers import generate_efficient_feat_dicts_opt\n",
    "from ridge_utils.tokenization_helpers import convert_to_feature_mats_opt\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Some parameters\n",
    "trim_start = 50 # Trim 50 TRs off the start of the story\n",
    "trim_end = 5 # Trim 5 off the back\n",
    "ndelays = 4 # We use 4 FIR delays (2 seconds, 4 seconds, 6 seconds, 8 seconds)\n",
    "delays = range(1, ndelays + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import engram_dir, allstories\n",
    "import os\n",
    "\n",
    "box_dir = os.path.join(engram_dir, 'huth_box/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data\n"
     ]
    }
   ],
   "source": [
    "box_dir = os.path.join(engram_dir, 'huth_box/')\n",
    "grids = joblib.load(os.path.join(box_dir, \"grids_huge.jbl\")) # Load TextGrids containing story annotations\n",
    "trfiles = joblib.load(os.path.join(box_dir, \"trfiles_huge.jbl\")) # Load TRFiles containing TR information\n",
    "\n",
    "wordseqs = make_word_ds(grids, trfiles)\n",
    "for story in wordseqs.keys():\n",
    "    wordseqs[story].data = [i.strip() for i in wordseqs[story].data]\n",
    "print(\"Loaded text data\")\n",
    "test_stories = ['wheretheressmoke']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.40it/s]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "import torch\n",
    "\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from huggingface_hub import login\n",
    "from transformer_lens.components import TransformerBlock\n",
    "from configs import huggingface_token\n",
    "\n",
    "login(token=huggingface_token)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2-2b\", device=device)\n",
    "tokenizer = model.tokenizer\n",
    "def override_to_local_attn(model, window_size=512):\n",
    "    for b in model.blocks:  # Possibly a cleaner way by correctly using 'use_local_attn'\n",
    "        if isinstance(b, TransformerBlock):\n",
    "            n_ctx = b.attn.cfg.n_ctx\n",
    "            attn_mask = torch.zeros((n_ctx, n_ctx)).bool()\n",
    "            for i in range(n_ctx):\n",
    "                start_idx = max(0, i-window_size)\n",
    "                attn_mask[i, start_idx:i+1] = True\n",
    "            b.attn.mask = attn_mask.to(device)\n",
    "\n",
    "override_to_local_attn(model)\n",
    "def find_word_boundaries(text_data, tokenizer):\n",
    "    full_story = \" \".join(text_data).strip()\n",
    "    tokenized_story = tokenizer(full_story)['input_ids']\n",
    "\n",
    "    word_boundaries = []  # In the tokenized story\n",
    "    curr_word_idx = 0\n",
    "    curr_word = text_data[curr_word_idx]\n",
    "    curr_token_set = []\n",
    "\n",
    "    if curr_word == '':\n",
    "        curr_word_idx += 1\n",
    "        curr_word = text_data[curr_word_idx]\n",
    "        word_boundaries.append(1)\n",
    "\n",
    "    for token_idx, token in enumerate(tokenized_story):\n",
    "        curr_token_set.append(token)\n",
    "        detokenized_chunk = tokenizer.decode(curr_token_set)\n",
    "        if curr_word in detokenized_chunk:\n",
    "            word_boundaries.append(token_idx)\n",
    "            curr_word_idx += 1\n",
    "            if curr_word_idx == len(text_data):\n",
    "                break\n",
    "            curr_word = text_data[curr_word_idx]\n",
    "            curr_token_set = []\n",
    "\n",
    "            if curr_word == '':  # Edge case\n",
    "                word_boundaries.append(token_idx)\n",
    "                curr_word_idx += 1\n",
    "                if curr_word_idx == len(text_data):\n",
    "                    break\n",
    "                curr_word = text_data[curr_word_idx]\n",
    "\n",
    "    return tokenized_story, word_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 2304)\n"
     ]
    }
   ],
   "source": [
    "llm_test_responses = []\n",
    "for test_story in test_stories:\n",
    "    ws = wordseqs[test_story]\n",
    "    text_data = ws.data\n",
    "    tokenized_story, word_boundaries = find_word_boundaries(text_data, tokenizer)\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(\n",
    "            torch.tensor(tokenized_story).to(device),\n",
    "            prepend_bos=True,\n",
    "            names_filter=lambda name: name.startswith('blocks.7.hook_resid_post'),\n",
    "        )\n",
    "    llm_response = cache['blocks.7.hook_resid_post'][0, word_boundaries, :]\n",
    "    llm_data_seq = DataSequence(llm_response.cpu().numpy(), ws.split_inds, ws.data_times, ws.tr_times)\n",
    "    interp_llm_response = llm_data_seq.chunksums('lanczos', window=3)\n",
    "    interp_llm_response = ridge_utils.npp.zs(interp_llm_response[10:-5])\n",
    "    llm_test_responses.append(interp_llm_response[40:])\n",
    "\n",
    "llm_test_responses = np.vstack(llm_test_responses)\n",
    "print(llm_test_responses.shape)\n",
    "del cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = make_delayed(llm_test_responses, delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensessions = joblib.load(os.path.join(box_dir, \"stored_activations\", \"tensessions_wheretheressmoke_S03.jbl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0)\n",
    "#selected_features = np.random.choice(tensessions.shape[-1], size=5000, replace=False)\n",
    "#np.random.seed()\n",
    "import pickle\n",
    "with open(os.path.join('pickles', 'voxel_indices', 'broca.pkl'), 'rb') as f:\n",
    "    broca_voxel_indices = pickle.load(f)\n",
    "selected_features = broca_voxel_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join('pickles', 'regression_weights', 'broca_gemma.pkl'), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    wt = results['regression_weights']\n",
    "    best_estimator = results['best_estimator']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot the weights with the features to get voxelwise model predictions\n",
    "#pred = (wt @ X_test.T).T\n",
    "\n",
    "X_test_scaled = best_estimator.named_steps['standardscaler'].transform(X_test)\n",
    "pred = best_estimator.named_steps['ridge'].predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred = pred\n",
    "_tensessions = tensessions[:, 40:, selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spe_and_cc_norm(orig_data, data_pred, data_norm=True, max_flooring=None):\n",
    "    '''\n",
    "    Computes the signal power explained and the cc_norm of a model given the observed and predicted values\n",
    "    Assumes normalization unless data_norm is set to False\n",
    "    \n",
    "    orig_data: 3D numpy array (trials, timepoints, voxels)\n",
    "    \n",
    "    data_pred: 2D numpy array (timepoints, voxels)\n",
    "    \n",
    "    data_norm: bool -> Set to False if not pre-normalized\n",
    "    \n",
    "    max_flooring: None/float (0-1) -> If not None, compute cc_norm in an alternate way that floors cc_max by max_flooring.\n",
    "    This is helpful to clean up bad voxels that are not at all language selective.\n",
    "    \n",
    "    According to Schoppe: https://www.frontiersin.org/articles/10.3389/fncom.2016.00010/full\n",
    "    '''\n",
    "    y = np.mean(orig_data, axis=0)\n",
    "    num_trials = len(orig_data)\n",
    "    if not data_norm:\n",
    "        variance_across_time = np.var(orig_data, axis=1, ddof=1)\n",
    "        TP = np.mean(variance_across_time, axis=0)\n",
    "    else:\n",
    "        TP = np.zeros(orig_data.shape[2]) + 1\n",
    "    SP = (1 / (num_trials-1)) * ((num_trials * np.var(y, axis=0, ddof=1)) - TP) \n",
    "    SPE_num = (np.var(y, axis=0, ddof=1) - np.var(y - data_pred, axis=0, ddof=1)) \n",
    "    SPE = (np.var(y, axis=0, ddof=1) - np.var(y - data_pred, axis=0, ddof=1)) / SP\n",
    "    y_flip = np.swapaxes(y, axis1=0, axis2=1)\n",
    "    data_flip = np.swapaxes(data_pred, axis1=0, axis2=1)\n",
    "    covs = np.zeros(y_flip.shape[0])\n",
    "    for i, row in enumerate(y_flip):\n",
    "        covs[i] = np.cov(y_flip[i], data_flip[i])[0][1]\n",
    "    cc_norm =  np.sqrt(1/SP) * (covs / np.sqrt(np.var(data_pred, axis=0, ddof=1)))\n",
    "    cc_max = None\n",
    "    if max_flooring is not None:\n",
    "        cc_max = np.nan_to_num(1 / (np.sqrt(1 + ((1/num_trials) * ((TP/SP)-1)))))\n",
    "        #cc_max = np.maximum(cc_max, np.zeros(cc_max.shape) + max_flooring)\n",
    "        corrs = np.zeros(y_flip.shape[0])\n",
    "        for i, row in enumerate(y_flip):\n",
    "            corrs[i] = np.corrcoef(y_flip[i], data_flip[i])[0][1]\n",
    "        cc_norm = corrs / cc_max\n",
    "    return SPE, cc_norm, cc_max, corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SPE, cc_norm, cc_max, corrs_unnorm = spe_and_cc_norm(_tensessions, _pred, max_flooring=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52306216  0.57816309  0.34997606  0.48494393  0.57933889  0.52554234\n",
      "  0.61742228  0.53106598  0.61956196  0.51546583  0.22517957  0.38098772\n",
      "  0.55239639  0.60992367  0.19449004  0.42044157  0.61146392  0.59042871\n",
      "  0.5947591   0.54436478  0.45487273  0.39807882  0.5507219   0.5200393\n",
      "  0.54715171  0.54521485  0.56516618  0.41968741  0.52250047  0.5722191\n",
      "  0.26318055  0.40014231  0.57260393  0.49024049  0.12282     0.38958659\n",
      "  0.45792718  0.63491117  0.72501937  0.40392629  0.17097398  0.3866783\n",
      "  0.48944281  0.45758972  0.43159321  0.56535964  0.18325378  0.45233034\n",
      "  0.49099377  0.29249715  0.64684436  0.52592798  0.42582982  0.57025656\n",
      "  0.6902258   0.61833333  0.52692826  0.50375847  0.62345084  0.56979755\n",
      "  0.54455661  0.4870111   0.35536884  0.52324193  0.1394122   0.18762186\n",
      "  0.17328535  0.35409999  0.44505306 -0.0722541   0.29828569  0.549152\n",
      "  0.5079588   0.61061848  0.4763922   0.49329106  0.5983255   0.55116793\n",
      "  0.64001929  0.67788043  0.57026348  0.6032646   0.68145742  0.60734976\n",
      "  0.65874256  0.74339668  0.58941371  0.63286851  0.5453559   0.67876701\n",
      "  0.77961102  0.46334112  0.31449158  0.51754431  0.11236177  0.10183521\n",
      "  2.53736817  0.62258772  0.38341898  0.54813431  0.55155055  0.53777017\n",
      "  0.70633932  0.76452527  0.63635183  0.4261758   0.71187781  0.63951929\n",
      "  0.69437714  0.70390396  0.58325647  0.41499858  0.34690909  0.55301249\n",
      "  0.72643043  0.65964959  0.65921682  0.67753373  0.67256412  0.6503001\n",
      "  0.63315811  0.60215287  0.54851642  0.57147828  0.55699838  0.62763335\n",
      "  0.61813283  0.50306515  0.58166087  0.48807259  0.6879414   0.60707328\n",
      "  0.4272655   0.33116457  0.65198945  0.45412599  0.42263225  0.48868233\n",
      "  0.63603418  0.55995434 -0.03087346  0.11387993  0.3431648   0.7846572\n",
      "  0.56869029  0.70554897  0.64564753  0.70893706  0.61378724  0.60676143\n",
      "  0.6909376   0.6082496   0.62362615  0.56932709  0.60928429  0.53323976\n",
      "  0.61446556  0.62758751  0.58329801  0.7404734   0.67180135  0.56845389\n",
      "  0.52215191  0.34733433  0.70886164  0.51450447 -0.00817969  0.5263839\n",
      "  0.52279658  0.24977652  0.36644273  0.52683753  0.48889159  0.37438762\n",
      "  0.37828694  0.4804942   0.44123386  0.47847961  0.06194362  0.27029554\n",
      "  0.49244055  0.43117827  0.70490691  0.74581123  0.88073314  0.70810361\n",
      "  0.66048289  0.52920354  0.61732971  0.39015071  0.19825319  0.6511652\n",
      "  0.52995271]\n",
      "[0.78168785 0.86768797 0.70724159 0.71117326 0.77990634 0.71428058\n",
      " 0.85690083 0.75538097 0.86708023 0.79475811 0.71099544 0.76124187\n",
      " 0.83483865 0.81310797 0.73148555 0.75739109 0.77607119 0.66465082\n",
      " 0.77034572 0.74815521 0.55765959 0.46146596 0.78792306 0.8629479\n",
      " 0.46747439 0.82032869 0.85648268 0.68650094 0.83482614 0.86170124\n",
      " 0.55754285 0.69677406 0.80948579 0.72597947 0.52061513 0.7448038\n",
      " 0.79462102 0.47566373 0.45205101 0.68416412 0.65069664 0.78712524\n",
      " 0.70872957 0.58275748 0.66356231 0.71521156 0.76114683 0.72675848\n",
      " 0.65982908 0.53528387 0.78685826 0.71027791 0.72227679 0.75069265\n",
      " 0.8091982  0.78285588 0.70623367 0.71814822 0.85546716 0.84344116\n",
      " 0.88829722 0.81548933 0.81988576 0.82117346 0.40436239 0.75227039\n",
      " 0.73043765 0.69741455 0.60353308 0.24742534 0.58651677 0.58031141\n",
      " 0.48081422 0.2280298  0.35408894 0.78838328 0.75718263 0.35880602\n",
      " 0.77420544 0.87268663 0.46870193 0.7460303  0.68344965 0.80067104\n",
      " 0.59886116 0.77185818 0.63654894 0.74498584 0.59476319 0.80713152\n",
      " 0.67175296 0.46034284 0.33876025 0.67681494 0.51649295 0.2164507\n",
      " 0.06589128 0.679135   0.41053377 0.27012686 0.84968242 0.44144252\n",
      " 0.73903289 0.88639792 0.87605828 0.45573797 0.52847514 0.72460851\n",
      " 0.64856028 0.72428171 0.84068618 0.53084786 0.68272047 0.73087638\n",
      " 0.69431601 0.84718623 0.48501868 0.89221558 0.70850772 0.8919938\n",
      " 0.84136489 0.71928018 0.76354705 0.81387467 0.65104915 0.91040041\n",
      " 0.84784217 0.73704486 0.59677402 0.36795626 0.84677742 0.87612254\n",
      " 0.65119948 0.71811721 0.80365053 0.76688517 0.41898453 0.71124849\n",
      " 0.73568554 0.85404239 0.39831541 0.43510977 0.41957559 0.44223391\n",
      " 0.8244421  0.84145212 0.75602002 0.77321493 0.8535928  0.80758486\n",
      " 0.90831311 0.83349366 0.89747778 0.83066832 0.9067991  0.8862476\n",
      " 0.92984139 0.90868914 0.91778653 0.80088333 0.81928149 0.81593076\n",
      " 0.80781213 0.77880516 0.56145833 0.70596652 0.46105851 0.57594173\n",
      " 0.60428008 0.45975135 0.55318999 0.63569798 0.65209313 0.53583258\n",
      " 0.77967973 0.89737649 0.72759671 0.60011635 0.40114417 0.74736116\n",
      " 0.87042819 0.811521   0.81794654 0.83959546 0.74888753 0.82737348\n",
      " 0.81345029 0.72059657 0.81089872 0.6274596  0.43963136 0.78607106\n",
      " 0.77359672]\n",
      "[ 0.40887134  0.50166515  0.24751763  0.34487915  0.45183008  0.37538469\n",
      "  0.52906967  0.40115713  0.53720992  0.40967065  0.16010165  0.29002381\n",
      "  0.46116186  0.49593379  0.14226666  0.3184387   0.47453954  0.39242893\n",
      "  0.45817013  0.40726934  0.25366414  0.18369983  0.43392649  0.44876682\n",
      "  0.25577941  0.44725538  0.48405505  0.2881158   0.43619705  0.49308191\n",
      "  0.14673444  0.27880878  0.46351474  0.35590453  0.06394195  0.29016557\n",
      "  0.36387856  0.30200421  0.32774574  0.27635188  0.1112522   0.30436425\n",
      "  0.34688259  0.26666383  0.28638899  0.40435175  0.13948303  0.32873491\n",
      "  0.32397197  0.15656901  0.50897483  0.37355503  0.30756699  0.42808741\n",
      "  0.55852947  0.48406588  0.37213447  0.36177324  0.53334172  0.48059071\n",
      "  0.48372812  0.39715236  0.29136185  0.42967239  0.05637305  0.14114237\n",
      "  0.12657415  0.24695448  0.26860425 -0.0178775   0.17494956  0.31867917\n",
      "  0.24423382  0.13923921  0.16868521  0.38890242  0.45304168  0.19776237\n",
      "  0.49550641  0.59157719  0.26728359  0.45005367  0.46574184  0.48628736\n",
      "  0.39449533  0.57379681  0.37519067  0.47147808  0.32435762  0.54785424\n",
      "  0.52370601  0.21329577  0.10653725  0.35028172  0.05803406  0.0220423\n",
      "  0.16719044  0.42282111  0.15740644  0.1480658   0.46864281  0.23739462\n",
      "  0.52200799  0.67767361  0.55748129  0.1942245   0.37620972  0.46340112\n",
      "  0.45034543  0.50982476  0.49033566  0.22030111  0.23684194  0.40418377\n",
      "  0.50437227  0.55884605  0.31973247  0.60450615  0.47651687  0.58006365\n",
      "  0.532717    0.43311663  0.41881809  0.46511169  0.36263332  0.57139766\n",
      "  0.52407908  0.37078158  0.34712009  0.17958936  0.58253324  0.53187058\n",
      "  0.27823507  0.23781498  0.52397167  0.34826249  0.17707637  0.34757457\n",
      "  0.46792115  0.47822474 -0.01229737  0.04955027  0.14398358  0.34700202\n",
      "  0.46885222  0.59368568  0.48812245  0.54816072  0.52392437  0.49001134\n",
      "  0.62758768  0.50697219  0.55969062  0.47292197  0.55249844  0.47258245\n",
      "  0.57135551  0.57028195  0.53534306  0.5930328   0.55039441  0.46381901\n",
      "  0.42180065  0.27050577  0.39799627  0.36322293 -0.00377132  0.30316645\n",
      "  0.31591556  0.11483509  0.20271245  0.33490956  0.31880285  0.20060909\n",
      "  0.29494266  0.4311842   0.3210403   0.28714343  0.02484832  0.20200839\n",
      "  0.42863414  0.34991022  0.57657616  0.62617972  0.65957006  0.58586615\n",
      "  0.53727     0.38134225  0.50059187  0.24480381  0.08715832  0.51186212\n",
      "  0.40996967]\n"
     ]
    }
   ],
   "source": [
    "print(cc_norm)\n",
    "print(cc_max)\n",
    "print(corrs_unnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_norm = np.array(cc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print((cc_norm == np.inf).sum())\n",
    "print((cc_norm == -np.inf).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cc_norm: 0.524\n",
      "Median cc_norm: 0.547\n",
      "Std cc_norm: 0.220\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "cc_norm_finite = cc_norm[~np.isinf(cc_norm)]\n",
    "plt.hist(cc_norm_finite, bins=50)\n",
    "plt.title('Histogram of cc_norm')\n",
    "plt.xlabel('cc_norm value')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean cc_norm: {np.mean(cc_norm_finite):.3f}\")\n",
    "print(f\"Median cc_norm: {np.median(cc_norm_finite):.3f}\") \n",
    "print(f\"Std cc_norm: {np.std(cc_norm_finite):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37021494686071754\n",
      "0.39242892610562996\n",
      "0.1540964407855528\n",
      "0.6776736098853463\n",
      "-0.017877495525880544\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(corrs_unnorm))\n",
    "print(np.median(corrs_unnorm))\n",
    "print(np.std(corrs_unnorm))\n",
    "print(np.max(corrs_unnorm))\n",
    "print(np.min(corrs_unnorm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
