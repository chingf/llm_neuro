{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6UyzFGfBSdA"
      },
      "source": [
        "# Understanding SAE Features with the Logit Lens\n",
        "\n",
        "This notebook demonstrates how to use the mats_sae_training library to perform the analysis documented the post \"[Understanding SAE Features with the Logit Lens](https://www.alignmentforum.org/posts/qykrYY6rXXM7EEs8Q/understanding-sae-features-with-the-logit-lens)\".\n",
        "\n",
        "As such, the notebook will include sections for:\n",
        "\n",
        "- Loading in GPT2-Small Residual Stream SAEs from Huggingface.\n",
        "- Performing Virtual Weight Based Analysis of features (specifically looking at the logit weight distributions).\n",
        "- Programmatically opening neuronpedia tabs to engage with public dashboards on [neuronpedia](https://www.neuronpedia.org/).\n",
        "- Performing Token Set Enrichment Analysis (based on Gene Set Enrichment Analysis).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff-PciWXBSdB"
      },
      "source": [
        "## Set Up\n",
        "\n",
        "Here we'll load various functions for things like:\n",
        "\n",
        "- downloading and loading our SAEs from huggingface.\n",
        "- opening neuronpedia from a jupyter cell.\n",
        "- calculating statistics of the logit weight distributions.\n",
        "- performing Token Set Enrichment Analysis (TSEA) and plotting the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vImmTg-8BSdC"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOd2C0e1BfN1",
        "outputId": "a3adf369-93ad-4a75-ea6d-24d476d5c6df"
      },
      "outputs": [],
      "source": [
        "from IPython import get_ipython  # type: ignore\n",
        "\n",
        "ipython = get_ipython()\n",
        "assert ipython is not None\n",
        "ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
        "ipython.run_line_magic(\"autoreload\", \"2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "YhU-Fmiibz26",
        "outputId": "ac0d4cda-1cab-4dfa-8ee0-5722a3094573"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/n/home04/cfang/.conda/envs/sae/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Feature statistics\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformer_lens import HookedTransformer\n",
        "\n",
        "from sae_lens.sae import SAE\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_feature_property_df(sae: SAE, feature_sparsity: torch.Tensor):\n",
        "    \"\"\"\n",
        "    feature_property_df = get_feature_property_df(sae, log_feature_density.cpu())\n",
        "    \"\"\"\n",
        "\n",
        "    W_dec_normalized = (\n",
        "        sae.W_dec.cpu()\n",
        "    )  # / sparse_autoencoder.W_dec.cpu().norm(dim=-1, keepdim=True)\n",
        "    W_enc_normalized = (sae.W_enc.cpu() / sae.W_enc.cpu().norm(dim=-1, keepdim=True)).T\n",
        "\n",
        "    d_e_projection = (W_dec_normalized * W_enc_normalized).sum(-1)\n",
        "    b_dec_projection = sae.b_dec.cpu() @ W_dec_normalized.T\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        {\n",
        "            \"log_feature_sparsity\": feature_sparsity + 1e-10,\n",
        "            \"d_e_projection\": d_e_projection,\n",
        "            # \"d_e_projection_normalized\": d_e_projection_normalized,\n",
        "            \"b_enc\": sae.b_enc.detach().cpu(),\n",
        "            \"b_dec_projection\": b_dec_projection,\n",
        "            \"feature\": list(range(sae.cfg.d_sae)),  # type: ignore\n",
        "            \"dead_neuron\": (feature_sparsity < -9).cpu(),\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_stats_df(projection: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Returns a dataframe with the mean, std, skewness and kurtosis of the projection\n",
        "    \"\"\"\n",
        "    mean = projection.mean(dim=1, keepdim=True)\n",
        "    diffs = projection - mean\n",
        "    var = (diffs**2).mean(dim=1, keepdim=True)\n",
        "    std = torch.pow(var, 0.5)\n",
        "    zscores = diffs / std\n",
        "    skews = torch.mean(torch.pow(zscores, 3.0), dim=1)\n",
        "    kurtosis = torch.mean(torch.pow(zscores, 4.0), dim=1)\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        {\n",
        "            \"feature\": range(len(skews)),\n",
        "            \"mean\": mean.numpy().squeeze(),\n",
        "            \"std\": std.numpy().squeeze(),\n",
        "            \"skewness\": skews.numpy(),\n",
        "            \"kurtosis\": kurtosis.numpy(),\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_all_stats_dfs(\n",
        "    gpt2_small_sparse_autoencoders: dict[str, SAE],  # [hook_point, sae]\n",
        "    gpt2_small_sae_sparsities: dict[str, torch.Tensor],  # [hook_point, sae]\n",
        "    model: HookedTransformer,\n",
        "    cosine_sim: bool = False,\n",
        "):\n",
        "    stats_dfs = []\n",
        "    pbar = tqdm(gpt2_small_sparse_autoencoders.keys())\n",
        "    for key in pbar:\n",
        "        layer = int(key.split(\".\")[1])\n",
        "        sparse_autoencoder = gpt2_small_sparse_autoencoders[key]\n",
        "        pbar.set_description(f\"Processing layer {sparse_autoencoder.cfg.hook_name}\")\n",
        "        W_U_stats_df_dec, _ = get_W_U_W_dec_stats_df(\n",
        "            sparse_autoencoder.W_dec.cpu(), model, cosine_sim\n",
        "        )\n",
        "        log_feature_sparsity = gpt2_small_sae_sparsities[key].detach().cpu()\n",
        "        W_U_stats_df_dec[\"log_feature_sparsity\"] = log_feature_sparsity\n",
        "        W_U_stats_df_dec[\"layer\"] = layer + (1 if \"post\" in key else 0)\n",
        "        stats_dfs.append(W_U_stats_df_dec)\n",
        "\n",
        "    return pd.concat(stats_dfs, axis=0)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_W_U_W_dec_stats_df(\n",
        "    W_dec: torch.Tensor, model: HookedTransformer, cosine_sim: bool = False\n",
        ") -> tuple[pd.DataFrame, torch.Tensor]:\n",
        "    W_U = model.W_U.detach().cpu()\n",
        "    if cosine_sim:\n",
        "        W_U = W_U / W_U.norm(dim=0, keepdim=True)\n",
        "    dec_projection_onto_W_U = W_dec @ W_U\n",
        "    W_U_stats_df = get_stats_df(dec_projection_onto_W_U)\n",
        "    return W_U_stats_df, dec_projection_onto_W_U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QmdAd_25BSdC"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tutorials'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msae_lens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneuronpedia_integration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_neuronpedia_quick_list\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Enrichment Analysis Functions\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtutorials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     get_enrichment_df,\n\u001b[1;32m     14\u001b[0m     manhattan_plot_enrichment_scores,\n\u001b[1;32m     15\u001b[0m     plot_top_k_feature_projections_by_token_and_category,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtutorials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     get_baby_name_sets,\n\u001b[1;32m     19\u001b[0m     get_letter_gene_sets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     get_gene_set_from_regex,\n\u001b[1;32m     23\u001b[0m )\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tutorials'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import plotly_express as px\n",
        "\n",
        "from transformer_lens import HookedTransformer\n",
        "\n",
        "# Model Loading\n",
        "from sae_lens import SAE\n",
        "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
        "\n",
        "# Enrichment Analysis Functions\n",
        "from tutorials.tsea import (\n",
        "    get_enrichment_df,\n",
        "    manhattan_plot_enrichment_scores,\n",
        "    plot_top_k_feature_projections_by_token_and_category,\n",
        ")\n",
        "from tutorials.tsea import (\n",
        "    get_baby_name_sets,\n",
        "    get_letter_gene_sets,\n",
        "    generate_pos_sets,\n",
        "    get_test_gene_sets,\n",
        "    get_gene_set_from_regex,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VEAe5FjBSdD"
      },
      "source": [
        "### Loading GPT2 Small and SAE Weights\n",
        "\n",
        "This will take a while the first time you run it, but will be quick thereafter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HQ904zDOBSdD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/n/home04/cfang/.conda/envs/sae/lib/python3.12/site-packages/sae_lens/sae.py:146: UserWarning: \n",
            "This SAE has non-empty model_from_pretrained_kwargs. \n",
            "For optimal performance, load the model like so:\n",
            "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
        "# this is an outdated way to load the SAE. We need to have feature spartisity loadable through the new interface to remove it.\n",
        "gpt2_small_sparse_autoencoders = {}\n",
        "gpt2_small_sae_sparsities = {}\n",
        "\n",
        "for layer in range(12):\n",
        "    sae, original_cfg_dict, sparsity = SAE.from_pretrained(\n",
        "        release=\"gpt2-small-res-jb\",\n",
        "        sae_id=f\"blocks.{layer}.hook_resid_pre\",\n",
        "        device=\"cpu\",\n",
        "    )\n",
        "    gpt2_small_sparse_autoencoders[f\"blocks.{layer}.hook_resid_pre\"] = sae\n",
        "    gpt2_small_sae_sparsities[f\"blocks.{layer}.hook_resid_pre\"] = sparsity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFYJKeNBSdD"
      },
      "source": [
        "# Statistical Properties of Feature Logit Distributions\n",
        "\n",
        "In the post I study layer 8 (for no particular reason). At the end of this notebook is code for visualizing these statistics across all layers. Feel free to change the layer here and explore different layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LEK1jEpEBSdD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>skewness</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>sparsity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.518076e-10</td>\n",
              "      <td>0.147306</td>\n",
              "      <td>0.181176</td>\n",
              "      <td>3.349324</td>\n",
              "      <td>-2.826817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.157533e-08</td>\n",
              "      <td>0.167641</td>\n",
              "      <td>0.123870</td>\n",
              "      <td>3.466492</td>\n",
              "      <td>-3.049473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-2.890037e-08</td>\n",
              "      <td>0.157237</td>\n",
              "      <td>0.097977</td>\n",
              "      <td>3.300671</td>\n",
              "      <td>-2.960210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-1.518076e-10</td>\n",
              "      <td>0.174304</td>\n",
              "      <td>0.133900</td>\n",
              "      <td>3.522123</td>\n",
              "      <td>-2.822145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.132864e-08</td>\n",
              "      <td>0.190366</td>\n",
              "      <td>0.212915</td>\n",
              "      <td>3.326519</td>\n",
              "      <td>-2.125533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24571</th>\n",
              "      <td>24571</td>\n",
              "      <td>1.408015e-08</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.320509</td>\n",
              "      <td>3.330733</td>\n",
              "      <td>-1.933250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24572</th>\n",
              "      <td>24572</td>\n",
              "      <td>3.596891e-08</td>\n",
              "      <td>0.163037</td>\n",
              "      <td>0.112237</td>\n",
              "      <td>3.468480</td>\n",
              "      <td>-3.279720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24573</th>\n",
              "      <td>24573</td>\n",
              "      <td>2.743922e-08</td>\n",
              "      <td>0.166876</td>\n",
              "      <td>0.311090</td>\n",
              "      <td>4.092549</td>\n",
              "      <td>-2.592994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24574</th>\n",
              "      <td>24574</td>\n",
              "      <td>1.643317e-08</td>\n",
              "      <td>0.170027</td>\n",
              "      <td>0.359409</td>\n",
              "      <td>3.876930</td>\n",
              "      <td>-3.186663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24575</th>\n",
              "      <td>24575</td>\n",
              "      <td>-2.136692e-08</td>\n",
              "      <td>0.256168</td>\n",
              "      <td>0.357178</td>\n",
              "      <td>2.617406</td>\n",
              "      <td>-2.580951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24576 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       feature          mean       std  skewness  kurtosis  sparsity\n",
              "0            0  1.518076e-10  0.147306  0.181176  3.349324 -2.826817\n",
              "1            1 -1.157533e-08  0.167641  0.123870  3.466492 -3.049473\n",
              "2            2 -2.890037e-08  0.157237  0.097977  3.300671 -2.960210\n",
              "3            3 -1.518076e-10  0.174304  0.133900  3.522123 -2.822145\n",
              "4            4  1.132864e-08  0.190366  0.212915  3.326519 -2.125533\n",
              "...        ...           ...       ...       ...       ...       ...\n",
              "24571    24571  1.408015e-08  0.205128  0.320509  3.330733 -1.933250\n",
              "24572    24572  3.596891e-08  0.163037  0.112237  3.468480 -3.279720\n",
              "24573    24573  2.743922e-08  0.166876  0.311090  4.092549 -2.592994\n",
              "24574    24574  1.643317e-08  0.170027  0.359409  3.876930 -3.186663\n",
              "24575    24575 -2.136692e-08  0.256168  0.357178  2.617406 -2.580951\n",
              "\n",
              "[24576 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# In the post, I focus on layer 8\n",
        "layer = 8\n",
        "\n",
        "# get the corresponding SAE and feature sparsities.\n",
        "sparse_autoencoder = gpt2_small_sparse_autoencoders[f\"blocks.{layer}.hook_resid_pre\"]\n",
        "log_feature_sparsity = gpt2_small_sae_sparsities[f\"blocks.{layer}.hook_resid_pre\"].cpu()\n",
        "\n",
        "W_dec = sparse_autoencoder.W_dec.detach().cpu()\n",
        "\n",
        "# calculate the statistics of the logit weight distributions\n",
        "W_U_stats_df_dec, dec_projection_onto_W_U = get_W_U_W_dec_stats_df(\n",
        "    W_dec, model, cosine_sim=False\n",
        ")\n",
        "W_U_stats_df_dec[\"sparsity\"] = (\n",
        "    log_feature_sparsity  # add feature sparsity since it is often interesting.\n",
        ")\n",
        "display(W_U_stats_df_dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>skewness</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>sparsity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.518076e-10</td>\n",
              "      <td>0.147306</td>\n",
              "      <td>0.181176</td>\n",
              "      <td>3.349324</td>\n",
              "      <td>-2.826817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.157533e-08</td>\n",
              "      <td>0.167641</td>\n",
              "      <td>0.123870</td>\n",
              "      <td>3.466492</td>\n",
              "      <td>-3.049473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-2.890037e-08</td>\n",
              "      <td>0.157237</td>\n",
              "      <td>0.097977</td>\n",
              "      <td>3.300671</td>\n",
              "      <td>-2.960210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-1.518076e-10</td>\n",
              "      <td>0.174304</td>\n",
              "      <td>0.133900</td>\n",
              "      <td>3.522123</td>\n",
              "      <td>-2.822145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.132864e-08</td>\n",
              "      <td>0.190366</td>\n",
              "      <td>0.212915</td>\n",
              "      <td>3.326519</td>\n",
              "      <td>-2.125533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24571</th>\n",
              "      <td>24571</td>\n",
              "      <td>1.408015e-08</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>0.320509</td>\n",
              "      <td>3.330733</td>\n",
              "      <td>-1.933250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24572</th>\n",
              "      <td>24572</td>\n",
              "      <td>3.596891e-08</td>\n",
              "      <td>0.163037</td>\n",
              "      <td>0.112237</td>\n",
              "      <td>3.468480</td>\n",
              "      <td>-3.279720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24573</th>\n",
              "      <td>24573</td>\n",
              "      <td>2.743922e-08</td>\n",
              "      <td>0.166876</td>\n",
              "      <td>0.311090</td>\n",
              "      <td>4.092549</td>\n",
              "      <td>-2.592994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24574</th>\n",
              "      <td>24574</td>\n",
              "      <td>1.643317e-08</td>\n",
              "      <td>0.170027</td>\n",
              "      <td>0.359409</td>\n",
              "      <td>3.876930</td>\n",
              "      <td>-3.186663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24575</th>\n",
              "      <td>24575</td>\n",
              "      <td>-2.136692e-08</td>\n",
              "      <td>0.256168</td>\n",
              "      <td>0.357178</td>\n",
              "      <td>2.617406</td>\n",
              "      <td>-2.580951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24576 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       feature          mean       std  skewness  kurtosis  sparsity\n",
              "0            0  1.518076e-10  0.147306  0.181176  3.349324 -2.826817\n",
              "1            1 -1.157533e-08  0.167641  0.123870  3.466492 -3.049473\n",
              "2            2 -2.890037e-08  0.157237  0.097977  3.300671 -2.960210\n",
              "3            3 -1.518076e-10  0.174304  0.133900  3.522123 -2.822145\n",
              "4            4  1.132864e-08  0.190366  0.212915  3.326519 -2.125533\n",
              "...        ...           ...       ...       ...       ...       ...\n",
              "24571    24571  1.408015e-08  0.205128  0.320509  3.330733 -1.933250\n",
              "24572    24572  3.596891e-08  0.163037  0.112237  3.468480 -3.279720\n",
              "24573    24573  2.743922e-08  0.166876  0.311090  4.092549 -2.592994\n",
              "24574    24574  1.643317e-08  0.170027  0.359409  3.876930 -3.186663\n",
              "24575    24575 -2.136692e-08  0.256168  0.357178  2.617406 -2.580951\n",
              "\n",
              "[24576 rows x 6 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W_U_stats_df_dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(5,2))\n",
        "plt.hist(W_U_stats_df_dec['skewness'], bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(5,2))\n",
        "plt.hist(np.log10(W_U_stats_df_dec['kurtosis']), bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(5,2))\n",
        "plt.hist(W_U_stats_df_dec['sparsity'], bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KuWSPqqjBSdE"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>skewness</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14215</th>\n",
              "      <td>14215</td>\n",
              "      <td>4.387646</td>\n",
              "      <td>55.515957</td>\n",
              "      <td>0.133079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19273</th>\n",
              "      <td>19273</td>\n",
              "      <td>3.638765</td>\n",
              "      <td>48.143673</td>\n",
              "      <td>0.115937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8992</th>\n",
              "      <td>8992</td>\n",
              "      <td>3.432152</td>\n",
              "      <td>44.810345</td>\n",
              "      <td>0.123028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>895</td>\n",
              "      <td>3.228184</td>\n",
              "      <td>42.953152</td>\n",
              "      <td>0.112418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       feature  skewness   kurtosis       std\n",
              "14215    14215  4.387646  55.515957  0.133079\n",
              "19273    19273  3.638765  48.143673  0.115937\n",
              "8992      8992  3.432152  44.810345  0.123028\n",
              "895        895  3.228184  42.953152  0.112418"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2214215%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2219273%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%228992%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%22895%22%7D%5D'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# then you can query accross combinations of the statistics to find features of interest and open them in neuronpedia.\n",
        "tmp_df = W_U_stats_df_dec[[\"feature\", \"skewness\", \"kurtosis\", \"std\"]]\n",
        "# tmp_df = tmp_df[(tmp_df[\"std\"] > 0.04)]\n",
        "# tmp_df = tmp_df[(tmp_df[\"skewness\"] > 0.65)]\n",
        "tmp_df = tmp_df[(tmp_df[\"skewness\"] > 3)]\n",
        "tmp_df = tmp_df.sort_values(\"skewness\", ascending=False).head(10)\n",
        "display(tmp_df)\n",
        "\n",
        "# if desired, open the features in neuronpedia\n",
        "get_neuronpedia_quick_list(sparse_autoencoder, list(tmp_df.feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14215    14215\n",
              "19273    19273\n",
              "8992      8992\n",
              "895        895\n",
              "Name: feature, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_df.feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHGG86wkBSdE"
      },
      "source": [
        "# Token Set Enrichment Analysis\n",
        "\n",
        "We now proceed to token set enrichment analysis. I highly recommend reading my AlignmentForum post (espeically the case studies) before reading too much into any of these results.\n",
        "Also read this [post](https://transformer-circuits.pub/2024/qualitative-essay/index.html) for good general perspectives on statistics here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tuqT9SBSdE"
      },
      "source": [
        "## Defining Our Token Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mUxqd6mBSdE"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "# get the vocab we need to filter to formulate token sets.\n",
        "vocab = model.tokenizer.get_vocab()  # type: ignore\n",
        "\n",
        "# make a regex dictionary to specify more sets.\n",
        "regex_dict = {\n",
        "    \"starts_with_space\": r\"Ġ.*\",\n",
        "    \"starts_with_capital\": r\"^Ġ*[A-Z].*\",\n",
        "    \"starts_with_lower\": r\"^Ġ*[a-z].*\",\n",
        "    \"all_digits\": r\"^Ġ*\\d+$\",\n",
        "    \"is_punctuation\": r\"^[^\\w\\s]+$\",\n",
        "    \"contains_close_bracket\": r\".*\\).*\",\n",
        "    \"contains_open_bracket\": r\".*\\(.*\",\n",
        "    \"all_caps\": r\"Ġ*[A-Z]+$\",\n",
        "    \"1 digit\": r\"Ġ*\\d{1}$\",\n",
        "    \"2 digits\": r\"Ġ*\\d{2}$\",\n",
        "    \"3 digits\": r\"Ġ*\\d{3}$\",\n",
        "    \"4 digits\": r\"Ġ*\\d{4}$\",\n",
        "    \"length_1\": r\"^Ġ*\\w{1}$\",\n",
        "    \"length_2\": r\"^Ġ*\\w{2}$\",\n",
        "    \"length_3\": r\"^Ġ*\\w{3}$\",\n",
        "    \"length_4\": r\"^Ġ*\\w{4}$\",\n",
        "    \"length_5\": r\"^Ġ*\\w{5}$\",\n",
        "}\n",
        "\n",
        "# print size of gene sets\n",
        "all_token_sets = get_letter_gene_sets(vocab)\n",
        "for key, value in regex_dict.items():\n",
        "    gene_set = get_gene_set_from_regex(vocab, value)\n",
        "    all_token_sets[key] = gene_set\n",
        "\n",
        "# some other sets that can be interesting\n",
        "baby_name_sets = get_baby_name_sets(vocab)\n",
        "pos_sets = generate_pos_sets(vocab)\n",
        "arbitrary_sets = get_test_gene_sets(model)\n",
        "\n",
        "all_token_sets = {**all_token_sets, **pos_sets}\n",
        "all_token_sets = {**all_token_sets, **arbitrary_sets}\n",
        "all_token_sets = {**all_token_sets, **baby_name_sets}\n",
        "\n",
        "# for each gene set, convert to string and  print the first 5 tokens\n",
        "for token_set_name, gene_set in sorted(\n",
        "    all_token_sets.items(), key=lambda x: len(x[1]), reverse=True\n",
        "):\n",
        "    tokens = [model.to_string(id) for id in list(gene_set)][:10]  # type: ignore\n",
        "    print(f\"{token_set_name}, has {len(gene_set)} genes\")\n",
        "    print(tokens)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxctX05KBSdE"
      },
      "source": [
        "## Performing Token Set Enrichment Analysis\n",
        "\n",
        "Below we perform token set enrichment analysis on various token sets. In practice, we'd likely perform tests accross all tokens and large libraries of sets simultaneously but to make it easier to run, we look at features with higher skew and select of a few token sets at a time to consider.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHwM7qVlBSdF"
      },
      "outputs": [],
      "source": [
        "features_ordered_by_skew = (\n",
        "    W_U_stats_df_dec[\"skewness\"].sort_values(ascending=False).head(5000).index.to_list()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxuiBx4NBSdF"
      },
      "outputs": [],
      "source": [
        "# filter our list.\n",
        "token_sets_index = [\n",
        "    \"starts_with_space\",\n",
        "    \"starts_with_capital\",\n",
        "    \"all_digits\",\n",
        "    \"is_punctuation\",\n",
        "    \"all_caps\",\n",
        "]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "\n",
        "# calculate the enrichment scores\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U,  # use the logit weight values as our rankings over tokens.\n",
        "    features_ordered_by_skew,  # subset by these features\n",
        "    token_set_selected,  # use token_sets\n",
        ")\n",
        "\n",
        "manhattan_plot_enrichment_scores(\n",
        "    df_enrichment_scores,\n",
        "    label_threshold=0,\n",
        "    top_n=3,  # use our enrichment scores\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ0n0aKTBSdF"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(\n",
        "    df_enrichment_scores.apply(lambda x: -1 * np.log(1 - x)).T,\n",
        "    x=\"starts_with_space\",\n",
        "    y=\"starts_with_capital\",\n",
        "    marginal_x=\"histogram\",\n",
        "    marginal_y=\"histogram\",\n",
        "    labels={\n",
        "        \"starts_with_space\": \"Starts with Space\",\n",
        "        \"starts_with_capital\": \"Starts with Capital\",\n",
        "    },\n",
        "    title=\"Enrichment Scores for Starts with Space vs Starts with Capital\",\n",
        "    height=800,\n",
        "    width=800,\n",
        ")\n",
        "# reduce point size on the scatter only\n",
        "fig.update_traces(marker=dict(size=2), selector=dict(mode=\"markers\"))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcmU_6I9BSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"1 digit\", \"2 digits\", \"3 digits\", \"4 digits\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BboYni5ZBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"nltk_pos_PRP\", \"nltk_pos_VBZ\", \"nltk_pos_NNP\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKrcnE7GBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"nltk_pos_VBN\", \"nltk_pos_VBG\", \"nltk_pos_VB\", \"nltk_pos_VBD\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKVdyyxoBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"nltk_pos_WP\", \"nltk_pos_RBR\", \"nltk_pos_WDT\", \"nltk_pos_RB\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYC3GFscBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvmgQ_YmBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"negative_words\", \"positive_words\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltYmy5lMBSdF"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(\n",
        "    df_enrichment_scores.apply(lambda x: -1 * np.log(1 - x))\n",
        "    .T.reset_index()\n",
        "    .rename(columns={\"index\": \"feature\"}),\n",
        "    x=\"negative_words\",\n",
        "    y=\"positive_words\",\n",
        "    marginal_x=\"histogram\",\n",
        "    marginal_y=\"histogram\",\n",
        "    labels={\n",
        "        \"starts_with_space\": \"Starts with Space\",\n",
        "        \"starts_with_capital\": \"Starts with Capital\",\n",
        "    },\n",
        "    title=\"Enrichment Scores for Starts with Space vs Starts with Capital\",\n",
        "    height=800,\n",
        "    width=800,\n",
        "    hover_name=\"feature\",\n",
        ")\n",
        "# reduce point size on the scatter only\n",
        "fig.update_traces(marker=dict(size=2), selector=dict(mode=\"markers\"))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5otoyu2SBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"contains_close_bracket\", \"contains_open_bracket\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlN-ScWhBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\n",
        "    \"1910's\",\n",
        "    \"1920's\",\n",
        "    \"1930's\",\n",
        "    \"1940's\",\n",
        "    \"1950's\",\n",
        "    \"1960's\",\n",
        "    \"1970's\",\n",
        "    \"1980's\",\n",
        "    \"1990's\",\n",
        "    \"2000's\",\n",
        "    \"2010's\",\n",
        "]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDmCs9OhBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"positive_words\", \"negative_words\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores, label_threshold=0.98).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilzC33VlBSdF"
      },
      "outputs": [],
      "source": [
        "token_sets_index = [\"boys_names\", \"girls_names\"]\n",
        "token_set_selected = {\n",
        "    k: set(v) for k, v in all_token_sets.items() if k in token_sets_index\n",
        "}\n",
        "df_enrichment_scores = get_enrichment_df(\n",
        "    dec_projection_onto_W_U, features_ordered_by_skew, token_set_selected\n",
        ")\n",
        "manhattan_plot_enrichment_scores(df_enrichment_scores).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0mTCic7BSdG"
      },
      "outputs": [],
      "source": [
        "tmp_df = df_enrichment_scores.apply(lambda x: -1 * np.log(1 - x)).T\n",
        "color = (\n",
        "    W_U_stats_df_dec.sort_values(\"skewness\", ascending=False)\n",
        "    .head(5000)[\"skewness\"]\n",
        "    .values\n",
        ")\n",
        "fig = px.scatter(\n",
        "    tmp_df.reset_index().rename(columns={\"index\": \"feature\"}),\n",
        "    x=\"boys_names\",\n",
        "    y=\"girls_names\",\n",
        "    marginal_x=\"histogram\",\n",
        "    marginal_y=\"histogram\",\n",
        "    # color = color,\n",
        "    labels={\n",
        "        \"boys_names\": \"Enrichment Score (Boys Names)\",\n",
        "        \"girls_names\": \"Enrichment Score (Girls Names)\",\n",
        "    },\n",
        "    height=600,\n",
        "    width=800,\n",
        "    hover_name=\"feature\",\n",
        ")\n",
        "# reduce point size on the scatter only\n",
        "fig.update_traces(marker=dict(size=3), selector=dict(mode=\"markers\"))\n",
        "# annotate any features where the absolute distance between boys names and girls names > 3\n",
        "for feature in df_enrichment_scores.columns:\n",
        "    if abs(tmp_df[\"boys_names\"][feature] - tmp_df[\"girls_names\"][feature]) > 2.9:\n",
        "        fig.add_annotation(\n",
        "            x=tmp_df[\"boys_names\"][feature] - 0.4,\n",
        "            y=tmp_df[\"girls_names\"][feature] + 0.1,\n",
        "            text=f\"{feature}\",\n",
        "            showarrow=False,\n",
        "        )\n",
        "\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwVcsxnkBSdG"
      },
      "source": [
        "## Digging into Particular Features\n",
        "\n",
        "When we do these enrichments, I generate the logit weight histograms by category using the following function. It's important to make sure the categories you group by are in the columns of df_enrichment_scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgndTFdFBSdG"
      },
      "outputs": [],
      "source": [
        "for category in [\"boys_names\"]:\n",
        "    plot_top_k_feature_projections_by_token_and_category(\n",
        "        token_set_selected,\n",
        "        df_enrichment_scores,\n",
        "        category=category,\n",
        "        dec_projection_onto_W_U=dec_projection_onto_W_U,\n",
        "        model=model,\n",
        "        log_y=False,\n",
        "        histnorm=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKP3u0D2BSdG"
      },
      "source": [
        "# Appendix Results: Logit Weight distribution Statistics Accross All Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhht2iCQBSdG"
      },
      "outputs": [],
      "source": [
        "W_U_stats_df_dec_all_layers = get_all_stats_dfs(\n",
        "    gpt2_small_sparse_autoencoders, gpt2_small_sae_sparsities, model, cosine_sim=True\n",
        ")\n",
        "\n",
        "display(W_U_stats_df_dec_all_layers.shape)\n",
        "display(W_U_stats_df_dec_all_layers.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok3DgORLBSdG"
      },
      "outputs": [],
      "source": [
        "# Let's plot the percentiles of the skewness and kurtosis by layer\n",
        "tmp_df = W_U_stats_df_dec_all_layers.groupby(\"layer\")[\"skewness\"].describe(\n",
        "    percentiles=[0.01, 0.05, 0.10, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
        ")\n",
        "tmp_df = tmp_df[[\"1%\", \"5%\", \"10%\", \"25%\", \"50%\", \"75%\", \"90%\", \"95%\", \"99%\"]]\n",
        "\n",
        "fig = px.area(\n",
        "    tmp_df,\n",
        "    title=\"Skewness by Layer\",\n",
        "    width=800,\n",
        "    height=600,\n",
        "    color_discrete_sequence=px.colors.sequential.Turbo,\n",
        ").show()\n",
        "\n",
        "\n",
        "tmp_df = W_U_stats_df_dec_all_layers.groupby(\"layer\")[\"kurtosis\"].describe(\n",
        "    percentiles=[0.01, 0.05, 0.10, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
        ")\n",
        "tmp_df = tmp_df[[\"1%\", \"5%\", \"10%\", \"25%\", \"50%\", \"75%\", \"90%\", \"95%\", \"99%\"]]\n",
        "\n",
        "fig = px.area(\n",
        "    tmp_df,\n",
        "    title=\"Kurtosis by Layer\",\n",
        "    width=800,\n",
        "    height=600,\n",
        "    color_discrete_sequence=px.colors.sequential.Turbo,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOkRZiunBSdG"
      },
      "outputs": [],
      "source": [
        "# let's make a pretty color scheme\n",
        "from plotly.colors import n_colors\n",
        "\n",
        "colors = n_colors(\"rgb(5, 200, 200)\", \"rgb(200, 10, 10)\", 13, colortype=\"rgb\")\n",
        "\n",
        "# Make a box plot of the skewness by layer\n",
        "fig = px.box(\n",
        "    W_U_stats_df_dec_all_layers,\n",
        "    x=\"layer\",\n",
        "    y=\"skewness\",\n",
        "    color=\"layer\",\n",
        "    color_discrete_sequence=colors,\n",
        "    height=600,\n",
        "    width=1200,\n",
        "    title=\"Skewness cos(W_U,W_dec) by Layer in GPT2 Small Residual Stream SAEs\",\n",
        "    labels={\"layer\": \"Layer\", \"skewnss\": \"Skewness\"},\n",
        ")\n",
        "fig.update_xaxes(showticklabels=True, dtick=1)\n",
        "\n",
        "# increase font size\n",
        "fig.update_layout(font=dict(size=16))\n",
        "fig.show()\n",
        "\n",
        "# Make a box plot of the skewness by layer\n",
        "fig = px.box(\n",
        "    W_U_stats_df_dec_all_layers,\n",
        "    x=\"layer\",\n",
        "    y=\"kurtosis\",\n",
        "    color=\"layer\",\n",
        "    color_discrete_sequence=colors,\n",
        "    height=600,\n",
        "    width=1200,\n",
        "    log_y=True,\n",
        "    title=\"log kurtosis cos(W_U,W_dec) by Layer in GPT2 Small Residual Stream SAEs\",\n",
        "    labels={\"layer\": \"Layer\", \"kurtosis\": \"Log Kurtosis\"},\n",
        ")\n",
        "fig.update_xaxes(showticklabels=True, dtick=1)\n",
        "\n",
        "# increase font size\n",
        "fig.update_layout(font=dict(size=16))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYNYdY3wBSdG"
      },
      "outputs": [],
      "source": [
        "# scatter\n",
        "fig = px.scatter(\n",
        "    W_U_stats_df_dec_all_layers[W_U_stats_df_dec_all_layers.log_feature_sparsity >= -9],\n",
        "    # W_U_stats_df_dec_all_layers[W_U_stats_df_dec_all_layers.layer == 8],\n",
        "    x=\"skewness\",\n",
        "    y=\"kurtosis\",\n",
        "    color=\"std\",\n",
        "    color_continuous_scale=\"Portland\",\n",
        "    hover_name=\"feature\",\n",
        "    # color_continuous_midpoint = 0,\n",
        "    # range_color = [-4,-1],\n",
        "    log_y=True,\n",
        "    height=800,\n",
        "    # width = 2000,\n",
        "    # facet_col=\"layer\",\n",
        "    # facet_col_wrap=5,\n",
        "    animation_frame=\"layer\",\n",
        ")\n",
        "fig.update_yaxes(matches=None)\n",
        "fig.for_each_yaxis(lambda yaxis: yaxis.update(showticklabels=True))\n",
        "\n",
        "# decrease point size\n",
        "fig.update_traces(marker=dict(size=5))\n",
        "fig.show()\n",
        "fig.write_html(\"skewness_kurtosis_scatter_all_layers.html\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
